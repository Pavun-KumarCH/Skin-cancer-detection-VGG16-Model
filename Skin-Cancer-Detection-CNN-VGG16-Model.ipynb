{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN1kL+L9FpD0G/Ov84WUWeO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavun-KumarCH/Skin-cancer-detection-VGG16-Model/blob/main/Skin-Cancer-Detection-CNN-VGG16-Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skin Cancer Classification with Machine Learning\n",
        "So this is where a machine learning algorithm works in the classification of Skin Cancer. As I mentioned earlier Skin Cancer can be easily cured in the early stages of the disease, but it’s the people who don’t want to visit the doctor.\n",
        "\n",
        "So here is a simple machine learning algorithm, which can help those people to identify if they are having skin cancer or not while sitting at their homes. This Machine Learning algorithm is based on Convolutional Neural Networks (CNN)."
      ],
      "metadata": {
        "id": "gXVud23tK_l4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Layer Classification for skin cancer detection\n"
      ],
      "metadata": {
        "id": "QHaqKxnlLVbT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK8_zGlmK8VY"
      },
      "outputs": [],
      "source": [
        "# Let Import required libraries\n",
        "import time\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tf_keras as keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import required tensorfloe modules\n",
        "from keras.layers import InputLayer, Conv2D, MaxPool2D, Dense, Flatten, Dropout"
      ],
      "metadata": {
        "id": "13dy6t00Zsep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will simply upload images to train our machine learning model using the skimage library in python."
      ],
      "metadata": {
        "id": "Sq7LOjCXL1Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgb = io.imread('b1.png')\n",
        "imgm = io.imread('m1.png')"
      ],
      "metadata": {
        "id": "g1pKhC4UL2xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These images are sample images of Benign mole and Malign mole which are a type of skin problems."
      ],
      "metadata": {
        "id": "mbFjF889SHfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets visualize this images"
      ],
      "metadata": {
        "id": "mwDwseTVP6NK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10, 20))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(imgb)\n",
        "plt.title(\"Benign\")\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(imgm)\n",
        "plt.title('Malign')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "wj65SVApP86I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets format the images to our requires size"
      ],
      "metadata": {
        "id": "5rYiFh5Uzv1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_image(image):\n",
        "  image = tf.image.resize(image[:, : ,:3],(128, 128))/255.\n",
        "  image = np.expand_dims(image, axis = 0)\n",
        "  return image\n",
        "\n",
        "imgb1 = format_image(imgb)\n",
        "\n",
        "print(imgb.shape)\n",
        "print(imgb1.shape)"
      ],
      "metadata": {
        "id": "Wp3HBh2XxO2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lets creates a model with the VGG16 architecture followed by a sequential model for binary classification."
      ],
      "metadata": {
        "id": "GFmAX8HWQtKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16 architecture\n",
        "\n",
        "model  = tf.keras.Sequential([\n",
        "\n",
        "    # Input layer\n",
        "    tf.keras.layers.InputLayer(input_shape = (128, 128, 3), name = 'Input_Layer'),\n",
        "\n",
        "    # Block 1\n",
        "    Conv2D(64, (3,3), padding = 'same', activation = 'relu', name = 'Block1_conv1'),\n",
        "    Conv2D(64, (3,3), padding = 'same', activation = 'relu', name = 'Block1_Conv2'),\n",
        "    MaxPool2D((2,2), strides = (2,2), name = 'Block__Maxpool'),\n",
        "\n",
        "    # Block 2\n",
        "    Conv2D(128, (3,3), padding = 'same', activation = 'relu', name = 'Block2_conv1'),\n",
        "    Conv2D(128, (3,3), padding = 'same', activation = 'relu', name = 'Block2_conv2'),\n",
        "    MaxPool2D((2,2), strides = (2,2), name = 'Block2_Maxpool'),\n",
        "\n",
        "    # Block 3\n",
        "    Conv2D(256, (3,3), padding = 'same', activation = 'relu', name = 'Block3_conv1'),\n",
        "    Conv2D(256, (3,3), padding = 'same', activation = 'relu', name = 'Block3_conv2'),\n",
        "    Conv2D(256, (3,3), padding = 'same', activation = 'relu', name = 'Block3_conv3'),\n",
        "    MaxPool2D((2,2), strides = (2,2), name = 'Block3_MaxPool'),\n",
        "\n",
        "    # Block 4\n",
        "    Conv2D(512, (3,3), padding = 'same', activation = 'relu', name = 'Block4_conv1'),\n",
        "    Conv2D(512, (3,3), padding = 'same', activation = 'relu', name = 'Block4_conv2'),\n",
        "    Conv2D(512, (3,3), padding = 'same', activation = 'relu', name = 'Block4_conv3'),\n",
        "    MaxPool2D((2,2), strides = (2,2), name = 'Block4_Maxpool'),\n",
        "\n",
        "    # Block 5\n",
        "    Conv2D(512, (3,3), padding = 'same', activation = 'relu', name = 'Block5_conv1'),\n",
        "    Conv2D(512, (3,3), padding = 'same', activation = 'relu', name = 'Block5_conv2'),\n",
        "    Conv2D(512, (3,3), padding = 'same', activation = 'relu', name = 'Block5_conv3'),\n",
        "    MaxPool2D((2,2), strides = (2,2), name = 'Block5_Maxpool'),\n",
        "\n",
        "    # Flatten\n",
        "    Flatten(),\n",
        "    Dense(256, activation = 'relu'),\n",
        "    Dense(units = 1, activation = 'sigmoid')\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "FsjzPOGTZV6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets save the model with time stamp\n",
        "\n"
      ],
      "metadata": {
        "id": "pQI_OvjJC43E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = time.time()\n",
        "t\n",
        "export_path = \"./{}.h5\".format(int(t))\n",
        "model.save(export_path)"
      ],
      "metadata": {
        "id": "FTR2W3FzDBel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the Model with weights and assets\n",
        "tf.saved_model.save(model, 'VGG16 Skin-cancer-detection')"
      ],
      "metadata": {
        "id": "dKIlLHNrCNrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "layer_dict\n"
      ],
      "metadata": {
        "id": "qXCFlgWa0hZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Now lets visualize the output of our trained model\n"
      ],
      "metadata": {
        "id": "cwsZH9NhqBW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is designed to extract the activations of a specific layer in a given neural network model when provided with an input image."
      ],
      "metadata": {
        "id": "oorFRDU97h4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras import backend as K\n",
        "\n",
        "def active_viewer(model, layer_name, im_put):\n",
        "    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "    layer = layer_dict[layer_name]\n",
        "    # Create a function using tf.keras.backend.function\n",
        "    activ_func = tf.keras.backend.function([model.input], [layer.output])\n",
        "    # Compute activations using the created function\n",
        "    activations = activ_func(im_put)\n",
        "    return activations\n",
        "\n",
        "active_benign = active_viewer(model,'Block2_conv1',imgb1)\n",
        "active_benign\n"
      ],
      "metadata": {
        "id": "o_CU0nmEAVzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function effectively reverses the preprocessing steps applied to neural network outputs, making them readable and suitable for visualization purposes."
      ],
      "metadata": {
        "id": "FMXAEByA7sqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def deprocess_image(x):\n",
        "  # normalize tensor: center on 0., ensure std is 0.1\n",
        "  x -= x.mean()\n",
        "  x /= (x.std() + 1e-5)\n",
        "  x *= 0.1\n",
        "\n",
        "  # clip [0, 1]\n",
        "  x += 0.5\n",
        "  x = np.clip(x, 0, 1)\n",
        "\n",
        "  # Convert to RGB array\n",
        "  x *= 255\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "    x = x.transpose(1, 2, 0)\n",
        "  x = np.clip(x, 0, 255).astype('uint8')\n",
        "  return x\n",
        "\n",
        "img_benign = deprocess_image(active_benign[0])\n",
        "print(img_benign[0])"
      ],
      "metadata": {
        "id": "GQ4eqH_Tt-5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is designed to visualize filters of a convolutional neural network."
      ],
      "metadata": {
        "id": "BPGwPGBR8Noq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_filters(filters):\n",
        "    new_image = np.zeros((16 * filters.shape[0], 8 * filters.shape[1]))  # Corrected shape initialization\n",
        "    for i in range(filters.shape[2]):\n",
        "        y = i % 8\n",
        "        x = i // 8\n",
        "        new_image[x * filters.shape[0]:x * filters.shape[0] + filters.shape[0],\n",
        "                  y * filters.shape[1]:y * filters.shape[1] + filters.shape[1]] = filters[:, :, i]  # Corrected typo\n",
        "    plt.figure(figsize=(10, 20))  # Moved outside the loop\n",
        "    plt.imshow(new_image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "plot_filters(img_benign[0])\n"
      ],
      "metadata": {
        "id": "oH1Wh_gFuNNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative"
      ],
      "metadata": {
        "id": "uGPHmJ8v8_MQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for n in range(128):\n",
        "  plt.subplot(8, 16, n+1)\n",
        "  plt.imshow(img_benign[0,:,:,n])\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "ZCSxkP7383mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets look at Malign"
      ],
      "metadata": {
        "id": "lBEtYlW59Z1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activ_malign = active_viewer(model,'Block2_conv1',imgm.reshape(1,128,128,3))\n",
        "img_malign = deprocess_image(activ_malign[0])\n",
        "plot_filters(img_malign[0])\n",
        "plt.figure(figsize=(20,20))\n"
      ],
      "metadata": {
        "id": "l_UAj0LxwvE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets zoom and visualize some of the filters"
      ],
      "metadata": {
        "id": "zJa61utgxDCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(121)\n",
        "plt.imshow(img_benign[0,:,:,34])\n",
        "plt.axis('off')\n",
        "plt.subplot(122)\n",
        "plt.imshow(img_malign[0,:,:,34])\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "-EFUxRfRw9gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(121)\n",
        "plt.imshow(img_benign[0,:,:,80])\n",
        "plt.axis('off')\n",
        "plt.subplot(122)\n",
        "plt.imshow(img_malign[0,:,:,80])\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "_Wbp4qvaAxgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Model\n",
        "Now let’s visualize and test the actual ability of our trained model"
      ],
      "metadata": {
        "id": "p1_Qe9jE_iDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_filters32(filters):\n",
        "    newimage = np.zeros((16*filters.shape[0],16*filters.shape[1]))\n",
        "    for i in range(filters.shape[2]):\n",
        "        y = i%16\n",
        "        x = i//16\n",
        "        newimage[x*filters.shape[0]:x*filters.shape[0]+filters.shape[0],\n",
        "                 y*filters.shape[1]:y*filters.shape[1]+filters.shape[1]] = filters[:,:,i]\n",
        "    plt.figure(figsize = (15,25))\n",
        "    plt.imshow(newimage)\n",
        "    plt.axis('off')\n",
        "\n",
        "active_benign = active_viewer(model,'Block3_conv1',imgb1.reshape(1,128,128,3))\n",
        "img_benign = deprocess_image(active_benign[0])\n",
        "plot_filters32(img_benign[0])"
      ],
      "metadata": {
        "id": "Z89m9w5o_VsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Malign"
      ],
      "metadata": {
        "id": "dPjPjjhV_64A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "active_malign = active_viewer(model,'Block3_conv1',imgm.reshape(1,128,128,3))\n",
        "img_malign = deprocess_image(active_malign[0])\n",
        "plot_filters32(img_malign[0])"
      ],
      "metadata": {
        "id": "dKInzbrt_6Nw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}